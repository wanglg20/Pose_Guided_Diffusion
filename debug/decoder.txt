  (0): TimestepEmbedSequential(
    (0): ResBlock(
      (in_layers): Sequential(
        (0): GroupNorm32(32, 1536, eps=1e-05, affine=True)
        (1): SiLU()
        (2): Conv2d(1536, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (h_upd): Identity()
      (x_upd): Identity()
      (emb_layers): Sequential(
        (0): SiLU()
        (1): Linear(in_features=768, out_features=1536, bias=True)
      )
      (out_layers): Sequential(
        (0): GroupNorm32(32, 768, eps=1e-05, affine=True)
        (1): SiLU()
        (2): Dropout(p=0.1, inplace=False)
        (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (skip_connection): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): AttentionBlock(
      (norm): GroupNorm32(32, 768, eps=1e-05, affine=True)
      (qkv): Conv1d(768, 2304, kernel_size=(1,), stride=(1,))
      (attention): QKVAttention()
      (proj_out): Conv1d(768, 768, kernel_size=(1,), stride=(1,))
    )
  )
  (1): TimestepEmbedSequential(
    (0): ResBlock(
      (in_layers): Sequential(
        (0): GroupNorm32(32, 1536, eps=1e-05, affine=True)
        (1): SiLU()
        (2): Conv2d(1536, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (h_upd): Identity()
      (x_upd): Identity()
      (emb_layers): Sequential(
        (0): SiLU()
        (1): Linear(in_features=768, out_features=1536, bias=True)
      )
      (out_layers): Sequential(
        (0): GroupNorm32(32, 768, eps=1e-05, affine=True)
        (1): SiLU()
        (2): Dropout(p=0.1, inplace=False)
        (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (skip_connection): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): AttentionBlock(
      (norm): GroupNorm32(32, 768, eps=1e-05, affine=True)
      (qkv): Conv1d(768, 2304, kernel_size=(1,), stride=(1,))
      (attention): QKVAttention()
      (proj_out): Conv1d(768, 768, kernel_size=(1,), stride=(1,))
    )
  )
  (2): TimestepEmbedSequential(
    (0): ResBlock(
      (in_layers): Sequential(
        (0): GroupNorm32(32, 1536, eps=1e-05, affine=True)
        (1): SiLU()
        (2): Conv2d(1536, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (h_upd): Identity()
      (x_upd): Identity()
      (emb_layers): Sequential(
        (0): SiLU()
        (1): Linear(in_features=768, out_features=1536, bias=True)
      )
      (out_layers): Sequential(
        (0): GroupNorm32(32, 768, eps=1e-05, affine=True)
        (1): SiLU()
        (2): Dropout(p=0.1, inplace=False)
        (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (skip_connection): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): AttentionBlock(
      (norm): GroupNorm32(32, 768, eps=1e-05, affine=True)
      (qkv): Conv1d(768, 2304, kernel_size=(1,), stride=(1,))
      (attention): QKVAttention()
      (proj_out): Conv1d(768, 768, kernel_size=(1,), stride=(1,))
    )
  )
  (3): TimestepEmbedSequential(
    (0): ResBlock(
      (in_layers): Sequential(
        (0): GroupNorm32(32, 1344, eps=1e-05, affine=True)
        (1): SiLU()
        (2): Conv2d(1344, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (h_upd): Identity()
      (x_upd): Identity()
      (emb_layers): Sequential(
        (0): SiLU()
        (1): Linear(in_features=768, out_features=1536, bias=True)
      )
      (out_layers): Sequential(
        (0): GroupNorm32(32, 768, eps=1e-05, affine=True)
        (1): SiLU()
        (2): Dropout(p=0.1, inplace=False)
        (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (skip_connection): Conv2d(1344, 768, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): AttentionBlock(
      (norm): GroupNorm32(32, 768, eps=1e-05, affine=True)
      (qkv): Conv1d(768, 2304, kernel_size=(1,), stride=(1,))
      (attention): QKVAttention()
      (proj_out): Conv1d(768, 768, kernel_size=(1,), stride=(1,))
    )
    (2): ResBlock(
      (in_layers): Sequential(
        (0): GroupNorm32(32, 768, eps=1e-05, affine=True)
        (1): SiLU()
        (2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (h_upd): Upsample()
      (x_upd): Upsample()
      (emb_layers): Sequential(
        (0): SiLU()
        (1): Linear(in_features=768, out_features=1536, bias=True)
      )
      (out_layers): Sequential(
        (0): GroupNorm32(32, 768, eps=1e-05, affine=True)
        (1): SiLU()
        (2): Dropout(p=0.1, inplace=False)
        (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (skip_connection): Identity()
    )
  )
  (4): TimestepEmbedSequential(
    (0): ResBlock(
      (in_layers): Sequential(
        (0): GroupNorm32(32, 1344, eps=1e-05, affine=True)
        (1): SiLU()
        (2): Conv2d(1344, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (h_upd): Identity()
      (x_upd): Identity()
      (emb_layers): Sequential(
        (0): SiLU()
        (1): Linear(in_features=768, out_features=1152, bias=True)
      )
      (out_layers): Sequential(
        (0): GroupNorm32(32, 576, eps=1e-05, affine=True)
        (1): SiLU()
        (2): Dropout(p=0.1, inplace=False)
        (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (skip_connection): Conv2d(1344, 576, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): AttentionBlock(
      (norm): GroupNorm32(32, 576, eps=1e-05, affine=True)
      (qkv): Conv1d(576, 1728, kernel_size=(1,), stride=(1,))
      (attention): QKVAttention()
      (proj_out): Conv1d(576, 576, kernel_size=(1,), stride=(1,))
    )
  )
  (5): TimestepEmbedSequential(
    (0): ResBlock(
      (in_layers): Sequential(
        (0): GroupNorm32(32, 1152, eps=1e-05, affine=True)
        (1): SiLU()
        (2): Conv2d(1152, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (h_upd): Identity()
      (x_upd): Identity()
      (emb_layers): Sequential(
        (0): SiLU()
        (1): Linear(in_features=768, out_features=1152, bias=True)
      )
      (out_layers): Sequential(
        (0): GroupNorm32(32, 576, eps=1e-05, affine=True)
        (1): SiLU()
        (2): Dropout(p=0.1, inplace=False)
        (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (skip_connection): Conv2d(1152, 576, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): AttentionBlock(
      (norm): GroupNorm32(32, 576, eps=1e-05, affine=True)
      (qkv): Conv1d(576, 1728, kernel_size=(1,), stride=(1,))
      (attention): QKVAttention()
      (proj_out): Conv1d(576, 576, kernel_size=(1,), stride=(1,))
    )
  )
  (6): TimestepEmbedSequential(
    (0): ResBlock(
      (in_layers): Sequential(
        (0): GroupNorm32(32, 1152, eps=1e-05, affine=True)
        (1): SiLU()
        (2): Conv2d(1152, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (h_upd): Identity()
      (x_upd): Identity()
      (emb_layers): Sequential(
        (0): SiLU()
        (1): Linear(in_features=768, out_features=1152, bias=True)
      )
      (out_layers): Sequential(
        (0): GroupNorm32(32, 576, eps=1e-05, affine=True)
        (1): SiLU()
        (2): Dropout(p=0.1, inplace=False)
        (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (skip_connection): Conv2d(1152, 576, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): AttentionBlock(
      (norm): GroupNorm32(32, 576, eps=1e-05, affine=True)
      (qkv): Conv1d(576, 1728, kernel_size=(1,), stride=(1,))
      (attention): QKVAttention()
      (proj_out): Conv1d(576, 576, kernel_size=(1,), stride=(1,))
    )
  )
  (7): TimestepEmbedSequential(
    (0): ResBlock(
      (in_layers): Sequential(
        (0): GroupNorm32(32, 960, eps=1e-05, affine=True)
        (1): SiLU()
        (2): Conv2d(960, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (h_upd): Identity()
      (x_upd): Identity()
      (emb_layers): Sequential(
        (0): SiLU()
        (1): Linear(in_features=768, out_features=1152, bias=True)
      )
      (out_layers): Sequential(
        (0): GroupNorm32(32, 576, eps=1e-05, affine=True)
        (1): SiLU()
        (2): Dropout(p=0.1, inplace=False)
        (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (skip_connection): Conv2d(960, 576, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): AttentionBlock(
      (norm): GroupNorm32(32, 576, eps=1e-05, affine=True)
      (qkv): Conv1d(576, 1728, kernel_size=(1,), stride=(1,))
      (attention): QKVAttention()
      (proj_out): Conv1d(576, 576, kernel_size=(1,), stride=(1,))
    )
    (2): ResBlock(
      (in_layers): Sequential(
        (0): GroupNorm32(32, 576, eps=1e-05, affine=True)
        (1): SiLU()
        (2): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (h_upd): Upsample()
      (x_upd): Upsample()
      (emb_layers): Sequential(
        (0): SiLU()
        (1): Linear(in_features=768, out_features=1152, bias=True)
      )
      (out_layers): Sequential(
        (0): GroupNorm32(32, 576, eps=1e-05, affine=True)
        (1): SiLU()
        (2): Dropout(p=0.1, inplace=False)
        (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (skip_connection): Identity()
    )
  )
  (8): TimestepEmbedSequential(
    (0): ResBlock(
      (in_layers): Sequential(
        (0): GroupNorm32(32, 960, eps=1e-05, affine=True)
        (1): SiLU()
        (2): Conv2d(960, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (h_upd): Identity()
      (x_upd): Identity()
      (emb_layers): Sequential(
        (0): SiLU()
        (1): Linear(in_features=768, out_features=768, bias=True)
      )
      (out_layers): Sequential(
        (0): GroupNorm32(32, 384, eps=1e-05, affine=True)
        (1): SiLU()
        (2): Dropout(p=0.1, inplace=False)
        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (skip_connection): Conv2d(960, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): AttentionBlock(
      (norm): GroupNorm32(32, 384, eps=1e-05, affine=True)
      (qkv): Conv1d(384, 1152, kernel_size=(1,), stride=(1,))
      (attention): QKVAttention()
      (proj_out): Conv1d(384, 384, kernel_size=(1,), stride=(1,))
    )
  )
  (9): TimestepEmbedSequential(
    (0): ResBlock(
      (in_layers): Sequential(
        (0): GroupNorm32(32, 768, eps=1e-05, affine=True)
        (1): SiLU()
        (2): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (h_upd): Identity()
      (x_upd): Identity()
      (emb_layers): Sequential(
        (0): SiLU()
        (1): Linear(in_features=768, out_features=768, bias=True)
      )
      (out_layers): Sequential(
        (0): GroupNorm32(32, 384, eps=1e-05, affine=True)
        (1): SiLU()
        (2): Dropout(p=0.1, inplace=False)
        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (skip_connection): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): AttentionBlock(
      (norm): GroupNorm32(32, 384, eps=1e-05, affine=True)
      (qkv): Conv1d(384, 1152, kernel_size=(1,), stride=(1,))
      (attention): QKVAttention()
      (proj_out): Conv1d(384, 384, kernel_size=(1,), stride=(1,))
    )
  )
  (10): TimestepEmbedSequential(
    (0): ResBlock(
      (in_layers): Sequential(
        (0): GroupNorm32(32, 768, eps=1e-05, affine=True)
        (1): SiLU()
        (2): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (h_upd): Identity()
      (x_upd): Identity()
      (emb_layers): Sequential(
        (0): SiLU()
        (1): Linear(in_features=768, out_features=768, bias=True)
      )
      (out_layers): Sequential(
        (0): GroupNorm32(32, 384, eps=1e-05, affine=True)
        (1): SiLU()
        (2): Dropout(p=0.1, inplace=False)
        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (skip_connection): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): AttentionBlock(
      (norm): GroupNorm32(32, 384, eps=1e-05, affine=True)
      (qkv): Conv1d(384, 1152, kernel_size=(1,), stride=(1,))
      (attention): QKVAttention()
      (proj_out): Conv1d(384, 384, kernel_size=(1,), stride=(1,))
    )
  )
  (11): TimestepEmbedSequential(
    (0): ResBlock(
      (in_layers): Sequential(
        (0): GroupNorm32(32, 576, eps=1e-05, affine=True)
        (1): SiLU()
        (2): Conv2d(576, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (h_upd): Identity()
      (x_upd): Identity()
      (emb_layers): Sequential(
        (0): SiLU()
        (1): Linear(in_features=768, out_features=768, bias=True)
      )
      (out_layers): Sequential(
        (0): GroupNorm32(32, 384, eps=1e-05, affine=True)
        (1): SiLU()
        (2): Dropout(p=0.1, inplace=False)
        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (skip_connection): Conv2d(576, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): AttentionBlock(
      (norm): GroupNorm32(32, 384, eps=1e-05, affine=True)
      (qkv): Conv1d(384, 1152, kernel_size=(1,), stride=(1,))
      (attention): QKVAttention()
      (proj_out): Conv1d(384, 384, kernel_size=(1,), stride=(1,))
    )
    (2): ResBlock(
      (in_layers): Sequential(
        (0): GroupNorm32(32, 384, eps=1e-05, affine=True)
        (1): SiLU()
        (2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (h_upd): Upsample()
      (x_upd): Upsample()
      (emb_layers): Sequential(
        (0): SiLU()
        (1): Linear(in_features=768, out_features=768, bias=True)
      )
      (out_layers): Sequential(
        (0): GroupNorm32(32, 384, eps=1e-05, affine=True)
        (1): SiLU()
        (2): Dropout(p=0.1, inplace=False)
        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (skip_connection): Identity()
    )
  )
  (12): TimestepEmbedSequential(
    (0): ResBlock(
      (in_layers): Sequential(
        (0): GroupNorm32(32, 576, eps=1e-05, affine=True)
        (1): SiLU()
        (2): Conv2d(576, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (h_upd): Identity()
      (x_upd): Identity()
      (emb_layers): Sequential(
        (0): SiLU()
        (1): Linear(in_features=768, out_features=384, bias=True)
      )
      (out_layers): Sequential(
        (0): GroupNorm32(32, 192, eps=1e-05, affine=True)
        (1): SiLU()
        (2): Dropout(p=0.1, inplace=False)
        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (skip_connection): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (13): TimestepEmbedSequential(
    (0): ResBlock(
      (in_layers): Sequential(
        (0): GroupNorm32(32, 384, eps=1e-05, affine=True)
        (1): SiLU()
        (2): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (h_upd): Identity()
      (x_upd): Identity()
      (emb_layers): Sequential(
        (0): SiLU()
        (1): Linear(in_features=768, out_features=384, bias=True)
      )
      (out_layers): Sequential(
        (0): GroupNorm32(32, 192, eps=1e-05, affine=True)
        (1): SiLU()
        (2): Dropout(p=0.1, inplace=False)
        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (skip_connection): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (14): TimestepEmbedSequential(
    (0): ResBlock(
      (in_layers): Sequential(
        (0): GroupNorm32(32, 384, eps=1e-05, affine=True)
        (1): SiLU()
        (2): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (h_upd): Identity()
      (x_upd): Identity()
      (emb_layers): Sequential(
        (0): SiLU()
        (1): Linear(in_features=768, out_features=384, bias=True)
      )
      (out_layers): Sequential(
        (0): GroupNorm32(32, 192, eps=1e-05, affine=True)
        (1): SiLU()
        (2): Dropout(p=0.1, inplace=False)
        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (skip_connection): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (15): TimestepEmbedSequential(
    (0): ResBlock(
      (in_layers): Sequential(
        (0): GroupNorm32(32, 384, eps=1e-05, affine=True)
        (1): SiLU()
        (2): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (h_upd): Identity()
      (x_upd): Identity()
      (emb_layers): Sequential(
        (0): SiLU()
        (1): Linear(in_features=768, out_features=384, bias=True)
      )
      (out_layers): Sequential(
        (0): GroupNorm32(32, 192, eps=1e-05, affine=True)
        (1): SiLU()
        (2): Dropout(p=0.1, inplace=False)
        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (skip_connection): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)